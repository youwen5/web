---
title: "A critique of AI in education"
published: 2025-06-15
---

// special-author: "Youwen Wu",
// location: "San Francisco, California",
// meta-description: "Writing 60 research project",
// enable-comments: true,
// subtitle: "Editor's note: if you're stumbling upon this—hi! This was an ethnographic research project I conducted as part of Writing 60 at UC Irvine.",

#import "@preview/html-shim:0.1.0": *
#import "@preview/showybox:2.0.4": showybox

#show: html-shim

#set cite(style: "modern-language-association-8")

#webimg(
  "https://pyxis.nymag.com/v1/imgs/bed/906/0c7c764b8c807add6e1a8f638b43ce2029-chat-gpt-college-lede.2x.rsocial.w600.gif",
  "hi chat",
  caption: [Graphic via #link("https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html")[_New York Magazine_.]],
)

= Abstract

The entire project of public education is in crisis. Falling literacy rates and
steady declines in almost every metric by which we measure student attainment
are a common theme across the United States. The latest solution from Big
Tech---after a long track record of EdTech overpromising and underdelivering
educational outcomes---seems to be AI chatbots. Marketed as research aides and
instantly accessible personal tutors that will pick up the slack left by
underfunded schools and demotivated teachers, educational institutions---both
at the K-12 and college level---seem to have no real answer to the rampant
cheating induced by these programs. So far, these chatbots have only seemed to
exacerbate the worst of our problems.

In this project, we explore the ramifications of the proliferation of AI
chatbots across high schools and colleges, and attempt to contextualize the
demand for this technology through an examination of the perverse incentives
we've placed at the heart of our education system. We develop an argument that
chatbots, while a uniquely difficult problem, are _also_ a symptom of the
broader structural issues embedded into our educational institutions. We place
particular focus on two interviews conducted with college students who recently
graduated high school amidst of the rise of AI, in addition to the experiences
of students, teachers, and administrators. We also examine formal academic
sources to identify broader trends and contextualize individual experience with
data.

By drawing from multiple personal perspectives from diverse backgrounds,
solidly buttressed against broader research and evidence, we hope to develop a
theory of not just _how_, but _why_ AI is reshaping education, and what can be
done about it.

#webimg(
  "https://cdn.youwen.dev/zotgpt.png",
  "ZotGPT",
  caption: [Do UCI students really need this?],
)

= Getting up to speed

Let's not pretend that ChatGPT is still failing basic arithmetic and failing to
count Rs in strawberry---the most sophisticated chatbots now produce outputs
more coherent and compelling than the majority of K-12 students, and arguably
many college students. They take no effort to use, and are increasingly
untraceable. So why would anyone write anything themselves, when an algorithm
can churn out better and faster prose at the literal press of a button? Is
there any reason why we _shouldn't_ teach every kid how to prompt ChatGPT
rather than toil away writing lukewarm essays by hand?

Last fall, Roy Lee transferred to Columbia University, after years of hard work
at community college. He then proceeded to generate every assignment he
received using ChatGPT, and he would "insert 20 percent of [his] humanity, [his]
voice, into it." He declared that "[most] assignments in college are not
relevant" and that they are "hackable" by AI @Walsh2025Cheating.

#btw[
  Funny story---it just so happens that I actually used to know Roy. I took
  dual enrollment classes at the community college he attended in the Bay Area
  before he transferred to Columbia. I was aware about his interview cheating
  tool months before it went viral. It's funny how these things work out.
]

How have we reached a point where even some of the best students in the
country, admitted to the most prestigious schools, view education with such
contempt and apathy, that they are eager to bypass the entire project using a
chatbot?

Lee is perhaps abnormally flagrant in his use of AI. But a study finds that a
quarter of US teens use ChatGPT for schoolwork---the actual number is almost
certainly higher @SidotiUSTeensChatGPT2025.

#webimg(
  "https://cdn.youwen.dev/chatgpt-iq.png",
  "ChatGPT what is my IQ?",
  caption: [What a thoughtful tool that will never mislead students.],
)

Here's the two pieces of the puzzle we'll look at. One---is introducing AI
chatbots into education harmful? Two---if it is, what incentives in our
education system are pushing students to rely on AI, even despite them possibly
knowing the detrimental effects? The story is more complex than simply student
laziness or underattainment, since even hardworking and high-achieving students
like Lee are caught up in it.

Before we dive deeper, let's clear something else up as well.

// These arguments are problematic and fail to hold up under scrutiny. Namely,
// there is a false equivalence being made in the claim that AI is the same sort
// of tool as the internet and computers are. Generative AI like #smallcaps[llm]s
// are a fundamentally different kind of technology that are designed explicitly
// to supplant learning and thinking rather than augmenting it. The equity
// argument presupposes that learning to use these tools substantially increases
// educational outcomes for a student, and that a student not using AI is falling
// behind their peers, which feels dubious.

When chatbots first released, many ridiculed them and proclaimed that they were
useless toys which could not produce any real meaningful outputs. Tech
companies got to work for 2 years---improving their capabilities to the point
where genuine nontrivial tasks could be performed to moderate or great success.
ChatGPT now is an entirely different story from the ChatGPT 3 years ago, in
terms of effectiveness in cheating on assignments.

I bring this up to highlight an important point about chatbots, and generative
AI in general, which we should keep in mind. We cannot criticize them solely,
or even primarily, on account of them producing poor outputs. Because the
companies producing them _will_ fix the bugs, and they'll keep making the tech
better. (Previously, ChatGPT essays were hilariously easy to spot and
universally nonsensical, even for high school writing. Now, a properly prompted
chatbot essay from a cutting-edge language model may exceed many high school
students' writing in quality.) Throughout this project, we will be more focused
on critique on the basis of how the use of AI tools itself is detrimental to
students, and view the rise of cheating with AI as an acceleration of an
existing force in our educational institutions that has already been at work
for years. We won't consider any criticisms based on the poor quality of AI
output, because I think those are by far the weakest.

So here's the goal---by the end, we should begin seeing why we should be
cautious when introducing AI into education, as well as how our incentives for
education need to change, such that even if chatbots and generative AI continue
advancing in capability, education continues to be valued.

= A couple conversations on education and AI

The best place to get a perspective on the state of education is presumably to
talk to the students themselves. Our goal---find out more about the forces
behind why a student like Roy Lee might head to one of the world's preeminent
educational institutions---and refuse to even study.

Towards this end, I spoke with two friends from high school, now in college,
and asked them what they thought. First, let's talk to Isaac, who now attends
UC Berkeley. (Both consented to the publication of their interviews.)

#webimg(
  "https://cdn.youwen.dev/isaac-mission-peak.jpg",
  "isaac (right)",
  extraImgClass: "max-w-80",
  caption: [Isaac (right) and a few other friends, at the summit of Mission Peak.],
)

#btw[
  Before reading, you may want to listen to the actual recording of the interview
  with Isaac---sorry, the one with Ananth is not available, the quality was
  terrible.

  #html.elem("audio", attrs: (controls: "", class: "mt-4"), {
    html.elem("source", attrs: (
      src: "https://cdn.youwen.dev/isaac-interview-edited.mp3",
      type: "audio/mpeg",
    ))
  })
]

== Why go to college & get educated?

#let isaac-q-a(question, answer) = {
  blockquote([
    *Youwen:* #emph(question)
    #linebreak()
    #linebreak()
    *Isaac:* #answer
  ])
}

#let ananth-q-a(question, answer) = {
  blockquote([
    *Youwen:* #emph(question)
    #linebreak()
    #linebreak()
    *Ananth:* #answer
  ])
}

#isaac-q-a[
  What do you think the purpose of college is right now for the average
  student?
][
  Yeah, so I think generally speaking, most people would
  agree that the large majority of people go to college to get a job and
  set themselves up for success in later life.

  I've had some experience, that have opened my eyes that. College really isn't
  just this I guess stepping stone you would say into future or into joining
  the workforce. But as for what I think college should be, I don't think it's
  unfair to treat college as a something or a stepping stone or something
  that's preparing you for work.

  Just with how expensive it is, people are paying like, \$200,000 to get
  a degree there. There should be some like tangible, materialistic
  benefit to getting a college degree, other than just like a intellectual
  development. But I do think that's like a very major aspect also of
  college.
]

Isaac makes a good point here. In principle, college shouldn't just a place to
get a degree for a high paying job later on, but rather a place to find and
improve yourself through education. However, the realities of our society also
heavily incentivize treating college as an investment on a later return. In
particular, the emphasis is on _results_---test scores, GPA, extracurriculars
to neatly fit on a resume---and not the process of learning itself. Throughout
this project I will be largely critical of this, with the understanding that it
is not a system any individual can opt out of.

Now let's speak with Ananth, who is now a rising sophomore at MIT. I asked him the same question.

#webimg(
  "https://zardini.mit.edu/img/people/AnanthVenkatesh.jpeg",
  "ananth venkatesh",
  caption: [Headshot of Ananth. Courtesy of the #link("https://zardini.mit.edu/people/ananth-venkatesh/")[MIT Zardini Lab].],
  extraImgClass: "max-w-64",
)

#ananth-q-a[
  What are your
  educational goals? And by that what do you hope to get out of college?
][
  I'm primarily interested in gaining some experience with research in these
  areas.

  And specifically different ways of thinking about very abstract problems in
  academia.
]

#ananth-q-a[
  That sounds very interesting. Broadly speaking, tell me what you see as the
  purpose of like college and education in general?
][
  The broader purpose of college is to prepare the greatest number of people to
  lead careers in academia and to do research in fundamental science and other
  disciplines that are going to truly result in some groundbreaking innovation.

  So I think unfortunately, a lot of American universities prioritize career
  readiness, people getting jobs, other trivialities over what should really be
  the fundamental goal of any institution of higher education, which is to
  prepare people to do research and really think about academic disciplines in
  new ways, because that is really the ultimate goal of humanity.

  And in doing so, we basically are able to achieve the most progress and the
  greatest innovation. So that should really be the goal of any policies
  surrounding higher education.
]

Ananth's view is interesting, and arguably rather uncommon. He says that a lot
of students have picked up the idea that college is some sort of a job training
center rather than an institution of higher learning.

This seems to be corroborated by our other accounts. James D. Walsh, in _New
York Magazine_'s _Intelligencer_, talks to a few students about AI. One of them
was our good friend Roy Lee from earlier, who explicitly sees college as
nothing more than a place to "meet your wife and [startup] co-founder."

Ultimately, it's this culture where the actual education matters less than the
_outcomes_ you can get from going to a prestigious university which heavily
incentivizes students to turn to AI to cheat on assignments.

== What do people think about AI?

#isaac-q-a[
  What has been the general attitude amongst classmates and your peers towards
  AI?
][
  The large sentiment from coming to college and in high school is that people
  just don't really care. Like, it's easy and it's accessible and I think people
  don't really feel they're hurting anybody from using it.
]

Studies corroborate this---students view AI as either positive or neutrally @ZieveCohenEtAl2023Balancing @SidotiUSTeensChatGPT2025.

#isaac-q-a[
  Tell me about people incorporating AI into their work. How do you square that
  with this other goal of college you talked about earlier, where it's not just
  to complete assignments, but to develop yourself?
][
  It's just, it's less fulfilling. Because of the resources available and the use
  of AI. Yeah I guess in general, I think the meaningfulness of it has just been
  diminished by people using AI.
]

== Why are students turning to AI?

#isaac-q-a[
  Why do you think so many students are turning to AI to
  complete their assignments or even to just assist them?
][
  And then if you see all your peers using it too, it just, it strongly
  incentivizes you to participate as well. So yeah, I would say just the, it's
  easy, it's accessible, and seeing your peers use it also is a motivator.
]

#isaac-q-a[
  Do you feel affected by it?
][
  Yeah, it's definitely tempting.

  [In] one of the most recent classes I had, we had this final paper and I had
  this buddy I was talking to because they gave us two months to write it. And
  I spent a lot of time on the paper and we were talking about it and it was
  like the day before it was due, he was like, "oh yeah, I'm just gonna use
  chat to write it up.

  It's frustrating 'cause you put all that work in.
]

A recent study shows a positive correlation between those who rely heavily on
AI and the personality trait of learned helplessness---demonstrated precisely
in this anecdote @AzeemPersonalityCorrelates2025. Isaac's friend can no longer
even write on their own, and they make no effort to change this.

#ananth-q-a[
  What's the general attitude amongst classmates and your peers towards AI? Are
  they generally open to using it?
][
  I think AI use is highly encouraged. People are generally using it to automate
  tedious tasks. I think especially in academia part of the appeal of AI agents
  is that we can just take a lot of these calculations or basically work that you
  had just assigned to someone else, and instead give it to an AI agency so you
  can clear your mind to think at a higher level of abstraction.

  And this is really a powerful new tool that we could be using to do research.
  So in general, I think there's widespread acceptance of AI tools.
]

What Ananth brings up is worth looking into. When you're operating at very high
levels, AI can be helpful in performing low-level repetitive tasks. Though
frankly, many students are not yet operating at these sorts of high levels
Ananth describes.

Additionally, we still need to be careful when considering the ethical
implications of AI, as things are often not as simple as they seem. For
example, teachers are using AI to accelerate their work, creating lesson plans
and grading assignments @GoldsteinTeachersAI. This seems benign on the surface,
but as we discuss further below, has profound ethical implications.

#ananth-q-a[
  Has you had any experience with, people using AI for [completing assignments]
  and how has it affected, if at all, your experience in classes?
][
  I think practically everyone uses that some form of AI
  tools on most assignments. And I think generally they're a tool, they're
  not able to solve like entire problems.

  So they're really only useful for getting like guiding principles or
  maybe regurgitating information from a lecture. But by themselves they
  have very limited capacity to solve, like intellectually challenging
  problems.
]

Around 26% of students are using AI for assignments @SidotiUSTeensChatGPT2025,
which is likely an underestimate. So, not quite the "everyone" Ananth
describes, but a significant chunk.

= A thought experiment about ethical AI use

In the previous section, we briefly touched on the ethics of AI use, and we
expound upon that here, in particular highlighting how "ethical AI use"
is often _not_ ethical upon further inspection.

In _Camera Obscura_, AI litigator Matthew Butterick makes the argument that
even as a tool, AI can be problematic. For instance, one use of AI that seems
benign which is raised by both Ananth in his interview and by some of the other
sources is to proofread/rewrite essays with better grammar and diction. To
further analyze this situation, Butterick formulates this thought experiment:
consider two teachers, Alice and Bob, who adopt different policies towards AI.

Alice's system allows students to draft their papers using AI, provided they
are responsible for all fact-checking and ensuring the paper meets all of the
expected guidelines.

Bob instead introduces an "AI essay validator" that takes in students' papers
and creates a "validated" version that is changed in either subtle or major
ways. Students must submit the validated versions of their paper.

It turns out that Bob's AI essay validator simply just secretly discards the
original essay and generates a new one to replace it with (with ChatGPT, etc.).

Most people would agree that Bob's system is obviously unethical. Some students
have their paper minimally changed, but others have entire core arguments
reformulated and rewritten. Clearly, the system is suppressing the free
expression of the students, and ensuring every paper is aligned with the biases
baked into the chatbot powering the AI essay validator.

But a lot of people would say that in contrast, Alice's system _is_ ethical. AI
is a tool, and it's not going away, so it doesn't make sense to restrict
students from using a tool, right? As long as they remain responsible for their
work and any mistakes, they simply become more efficient writers.

Butterick argues that, in fact, there is no morally relevant difference between
Alice's and Bob's systems. True, Alice's is more transparent, which is a boon.
But in either case, students' thoughts and free speech are effectively being
suppressed in exactly the same way---by being filtered through an AI chatbot.
In Alice's case, it's just being done voluntarily by students with her
permission---but the outcome is effectively the same.

So if you agree with the argument above---and accept that Bob is clearly acting
unethically---then it's clearly unethical to permit students to draft papers
with AI as well.

We already have a culture of exclusivity in academia built around "academic"
language and writing, but AI gives everyone a way to write in an "academic"
way. When there are real advantages for many students to adopt an unaffected
academic tone over their own less polished writing, it's clear why they would
turn to chatbots to regurgitate their writing into a generic but polished form.
But as we discussed above, this is effectively equivalent to filtering them
through Teacher Bob's fake essay validator, and detrimental to both the
students and the free exchange of thought in general.

== Tangible impacts

#isaac-q-a[
  Do you see any kind of negative impacts on your peers when they are so reliant [on AI]?
][
  I remember at the end of the semester, they [a friend in college] actually told
  me that they were like, they felt incapable of actually like writing an
  essay.

  I really do think if you become totally self-reliant on it, like that,
  it just becomes a crutch and it prohibits you from actually growing.
]

Another student named Wendy interviewed by Walsh in _Intelligencer_, this time
a freshman finance major, says that she is against "copy and pasting" and
"cheating and plagiarism." But she relies heavily on AI tools for essay
writing. She has it down to a science---first, she tells the AI not to use
advanced English because she is a freshman. Then, she provides some background
on the class to make sure the writing is in the correct context, followed by
the actual assignment instructions. Finally, she asks for an outline of the
essay to write---the main points of each paragraph, the general structure and
organization. Then all that remains is to write the essay herself, with the
outline provided by the chatbot.

Again, this is a process that feels responsible and ethical at first glance.
Indeed, Wendy is not even downright contemptuous of education like Lee---she
acknowledges that copy-pasting and plagiarism are wrong. But clearly she feels
that her approach is responsible and uses AI constructively. However, her
approach clearly just takes us back to a situation like Bob's essay
validator---only in this case, rather than having the entire essay generated,
she generates all of the _ideas_ and writes them into prose herself, turning
writing from a research process into a fill-in-the-blank.

#webimg(
  "https://brevity.wordpress.com/wp-content/uploads/2023/02/screen-shot-2023-02-08-at-2.44.01-pm.png",
  "mad libs",
  caption: [Wendy's AI use reduces her involvement to essentially playing Mad Libs.],
  extraImgClass: "max-w-80",
)

Absurdly, Wendy actually fully recognizes the importance of the research process.
#blockquote[
  “Honestly,” she continued, “I think there is beauty in trying to plan your
  essay. You learn a lot. You have to think, Oh, what can I write in this
  paragraph? Or What should my thesis be? ”
]
But in high school english class, back when she wrote her own essays, she would
get bad grades. Now, with the help of ChatGPT, she gets good grades
effortlessly with her new method. "An essay with ChatGPT, it's like it just
gives you straight up what you have to follow. You just don't really have to
think that much."

In their study, #cite(<ZieveCohenEtAl2023Balancing>, form: "author") note that
in some interviews they conducted with students, when asked about whether a
student uses the school's "Writing Center" for help, it carries a negative
connotation (the writing center was for people with "problems with writing"),
while asking if they used ChatGPT for assistance carried no such negative
connotations.

In Wendy's case, she clearly care more about the final result (her grade in the
course) than her actual learning. Wendy _knows_ that it'd be better for her to
do her own writing (ironically, the essay she wrote with the help of AI was
literally about how learning is what makes us human), but getting a good grade
is more important to her. With the students in
#cite(<ZieveCohenEtAl2023Balancing>, form: "author")'s study, they see working
to improve their writing skills as a sign that there was a _problem_ with their
writing in the first place, while using ChatGPT to assist with drafting or
brainstorming is totally fine.

#webimg(
  "https://www.pewresearch.org/wp-content/uploads/sites/20/2023/11/SR_23.11.21_ai-roundup_2.png",
  "chart about american views of AI",
  caption: [Many Americans take Wendy's view---that it's acceptable to use AI as long as the final writing is done by the student.],
)

In either case, rather than being incentivized to prioritize their actual
learning (even when they are aware of it, like Wendy) and work to improve their
skills in areas they are weak in, ChatGPT provides an easy out. Under a system
where the only way through is getting good grades and a high #smallcaps[gpa],
it is clear why students take the easy way through. As Ananth mentioned, if the
focus is primarily on maintaining high grades for college admissions, or for
job recruitment, then actual skills and education will always fall to the
wayside in favor of whatever flawed metrics jobs and colleges targeting. The
system has been like this, for a long time. With AI, this divide has only
become far more pronounced (it used to take actual effort to cheat
effectively!).

#ananth-q-a[
  Are there any unexpected consequences to the widespread adoption [of AI]?
][
  I think a recent one is Grok AI, which was released by Elon Musk, has started
  talking about white genocide and the Boer genocide in South Africa. Which is
  very interesting because it's been able to turn any conversation into a
  conversation about white genocide, really furthering the views of the fascist
  administration and bringing in these geopolitical issues into the Twitter
  mainstream, where you have all of these very interesting individuals engaging
  in political discussions with AI chatbot that seems to have grown a mind of its
  own after being indoctrinated by Elon Musk.

  I think that's a very interesting example of where you can have new behaviors
  and especially unexpected behaviors emerge from some set of training.
]

#webimg(
  "https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40228a08-5457-4884-b223-01bbd9cb44c4_2358x967.png",
  "grok white genocide",
  caption: [Pictured: Elon Musk's Grok AI chatbot, after it was deliberately programmed to derail unrelated conversations into white genocide conspiracy theories. Can we really trust this thing to teach kids about history?],
)

#ananth-q-a[
  If you have AI not just influence people online, but it's deployed into the
  education system, then if it's sapping people of the ability to do critical
  thinking for people and they're not making their own choices in school, do
  you feel that kind of bleeds out into society at large?
][
  Yeah, certainly. I think definitely schools and education are a huge part of
  achieving achieving greater awareness for what the values and political
  system look like. Helping educate people about their role in society and
  civic duties. But. I think, yeah, you definitely need to restructure the
  education system to look at things from a more investigative research based
  manner where we look at, how do we actually improve the political system?

  People generally do not have any coherent political beliefs. So that leads to
  a lot of erosion of democracy that could significantly be improved if we had
  better education system.
]

#webimg(
  "https://static01.nyt.com/images/2023/02/07/technology/disinfp-chatgpt-promos-promo/disinfp-chatgpt-promos-promo-videoSixteenByNineJumbo1600.jpg?year=2023&h=901&w=1600&s=a4544c195933ddec6e3f4d16ccf41a1eccbc58a2437d6eb9aab45d3c5bc49cdd&k=ZQJBKqZ0VN&tw=1",
  "chatgpt instructed to write about Alex Jones conspiracy theories about Sandy Hook",
  caption: [ChatGPT makes it significantly easier for anyone to generate massive amounts of credible-looking misinformation.],
)

== Solutions?

We talked for a bit about what solutions we could envision---but none seemed
very compelling.

#isaac-q-a[
  What does [higher ed and K-12] need to do so that students are less
  incentivized to take the path of least resistance, which in this case is AI?
][
  It's challenging just 'cause of how accessible it is.

  I tutor kids online and I
  had this one sixth grader that I tutored. Their parent or their mom
  actually came to me and she was talking about how she found out that he
  had recently discovered ChatGPT and was using it for all his
  assignments.

  And she had asked me to talk with him about it, and I did. And I think
  we had a productive conversation. I think hopefully he, he is, he'd be
  more discouraged to use AI in the future. And I think just having those
  conversations from figures of authority and the future generations'
  lives that could be productive and possibly prevent like using AI as a
  crutch.
]

Teachers have been trying their best to deal with AI by having productive
conversations with their students and implementing changes in their lesson
plans @Waxman2023Creative. Some examples: responsibling disclosing the use of
AI, prompting the AI to help generate ideas, not write the essays, and using AI
for feedback on work. Referring back to our previous discussions, we can
already see how these methods may be ethically dubious.

At the end of the day, it seems that there is not really a foolproof method to
allowing students to coexist with AI in the classroom.

== Conclusion

So what exactly can we do? As a rule, schools should probably ban AI. I also
believe that most won't, because this problem is structural and the roots of
which reach deep into educational institutions. Indeed, no university wants to
be seen as the anti-progress institution that isn't embracing this
revolutionary new technology. Deeper than that, if we are to make any progress
on the cultural front (i.e. making students actually care about their work such
that they don't feel compelled to complete it with AI), we need to reorient the
view that getting your education is just a means to an end (getting into a good
college, high paying job, etc.) into viewing education as a worthwhile end in
and of itself.

For starters---on a local level, K--12 teachers should probably start doing all
their assignments in-class, on paper again. College professors are already
returning to blue books and primarily in-person assessments. School districts
and universities can adopt stricter policies to minimize activities which are
easy for students to cheat on with AI. All of these are things that can be done
in individual classrooms or schools.

But the educational and cultural reform we are really looking for goes beyond
any individual policies. For one---though I've been critical of the idea that
education should be a means to a high paying job---we cannot expect people in a
society as unequal and unforgiving as ours to not view education as primarily a
social mobility ladder. So a real fix will likely come from a progressive
movement larger than even the education system itself.

In the meantime, within education in particular, we should work to reduce the
stigma around failure and place more emphasis on improvement and progress.
Earlier, we discussed Wendy and the other students who used AI because they
didn't want to try and genuinely improve their skills, out of fear of bad
grades or social stigma.

Thanks to AI, it's now easier than ever for students to avoid taking risks and
applying themselves to their education. In response, it's more important than
ever for the education system to be more lenient with mistakes, de-emphasize
conformance with the status quo, and allow people to experiment and fall.

#show bibliography: it => {
  html.elem(
    "div",
    attrs: (
      class: "math min-w-full w-0 overflow-x-auto flex justify-center min-w-full w-0 overflow-x-auto",
    ),
    html.frame(it),
  )
}

#bibliography("refs.bib", full: true)

= Annotated bibliography<annotated-bib>

#let bluebox(citation, body) = html.elem(
  "div",
  attrs: (
    class: "py-2 px-4 text-[0.8em] rounded-md border-1 border-slate-200 dark:border-zinc-700 bg-slate-50 dark:bg-overlay leading-[1.5em] my-3",
  ),
  {
    html.elem(
      "p",
      attrs: (class: "border-b-1 border-b-foreground pb-2"),
      citation,
    )
    body
  },
)


#[
  #set cite(form: "full")

  #bluebox[@Walsh2025Cheating][
    This _New York Magazine_ article is a long discussion of a few particular
    students' experiences with ChatGPT and other chatbots. It begins with a
    student at Columbia University named Roy Lee, who expresses his disdain for
    the education system and college. He built a ChatGPT powered interview
    cheating tool that gives people an invisible AI assistant overlay in Zoom
    interviews to answer questions for them. In his eyes, school is nothing
    more than a place to network ("It's the best place to meet your
    co-founder and your wife") and assignments are "hackable" and
    worthless (since they can be done by ChatGPT). This sentiment really
    captures exactly the rot in the education system that I'm looking to
    describe---the incentives are such that everyone sees education as a career
    advancement opportunity. This starts at "where will we use this in real
    life?" in math class and ends with someone like Roy, declaring his entire
    core college education as "worthless" because it's not helping him build
    his startup. The rest of the article also goes over a few really good
    anecdotes and interviews, which will be very useful in my project.

    Funny story---I actually used to know Roy in high school. I took dual
    enrollment classes at the community college he attended in the Bay Area
    before he transferred to Columbia. He texted me about his interview
    cheating tool months before it went viral---he originally wanted to recruit
    me to work on it. It's funny how these things work out. Also, he was just
    as insufferable in person as the article portrays him.
  ]


  #bluebox[@NewClassroomsInterviewAI2024][
    This is an interview with a few former school administrators discussing the
    role of AI in education. It takes an positive and optimistic tone, talking
    about the many "exciting opportunities" AI can bring in the short term.
    They also advocate for longer-term structural change---to better integrate
    AI, to produce the "educational outcomes we want this technology to
    create."

    I selected this interview because it's a perspective from school admin, not
    teachers or students, which we've been looking at primarily. The interests
    of administrators are unfortunately often not entirely aligned in the
    best interest of students and teachers. Also, note that these former
    administrators now work for an EdTech-adjacent company called New
    Classrooms. Their perspective, then, is similar to that of tech companies,
    that we should integrate AI into education because it's _obviously_ good.
  ]


  #bluebox[@Kelly2023OpenPolicy][
    This is an article/interview with a professor (Professor Mollick) who has adopted an "Open
    ChatGPT Policy." He says that since students will use it anyways, he might
    as well integrate it officially into his syllabus.

    This seems to be a common occurrence across universities. (Indeed, Writing 60 seems to have done this too. It's a sensible conclusion to draw.) But one particular remark I'd like to note is near the end:
    #blockquote[
      Mollick agrees, but isn't convinced that educators can ever truly stop cheating.

      "I don't think human nature changes as a result of ChatGPT. I think
      capability did."
    ]
    Mollick says that everyone cheating with ChatGPT is just human nature and
    there's nothing we can do about it. I disagree. There are actions that can
    be taken now, as well as policy changes and fundamental restructurings that
    need to happen, but we needn't accept the way things are going as human
    nature.
  ]


  #bluebox[@GoldsteinTeachersAI][
    An article about educators experimenting with using AI to help accelerate
    their work. Jon Gold, a middle school history teacher, uses generative AI
    for lesson planning by feeding it curriculum pages. But, he says that he
    does not want students to use AI themselves to write the essays he assigns.
    Here we see a complicated dynamic---AI can legitimately help overworked and
    underpaid teachers do work much faster. But the quality is dubious, and, it
    would be far more sensible to just not underpay or overwork them.

    The article also shows a general attitude of educators being in favor of
    "AI literacy." We see two formulations, broadly. One is to teach students
    how to use AI effectively. I think this is unnecessary, and as other
    sources show, detrimental. The other is that students should understand the
    limitations of the technology and how it can be wrong. I think this is
    important.
  ]


  #bluebox[@ZieveCohenEtAl2023Balancing][
    A study conducted to analyze sentiment towards AI amongst students, through
    in-depth, structured interviews conducted over Zoom. 33% expressed negative
    attitudes, 40% expressed positive, and 26.7% were neutral. Students
    "demonstrated awareness and thoughtfulness regarding their use of ChatGPT."
    It also mentions that in some interviews, when asked about whether a
    student uses the "Writing Center" for help, it carries a negative
    connotation as if the writing center was for people with "problems," while
    ChatGPT had no such connotations. Perhaps this is worth looking further
    into.
  ]


  #bluebox[@ButterickCameraObscura2025][
    This is an opinion piece that also incorporates some teacher perspectives.
    The author is a lawyer who is currently litigating against ChatGPT and
    other AI tools for alleged copyright infringement. The article makes an
    argument for why AI shouldn't be incorporated into the education system,
    arguing that we don't just aim to teach facts to children in schools.
    Rather, the process of research and critically examining sources of
    information is more important. Even if AI could research and produce
    information that students need only fact check, students should still be
    researching on their own.
  ]


  #bluebox[@AzeemPersonalityCorrelates2025][
    This is an academic study on personality traits that arise/are associated
    with from reliance on GenAI tools. In particular, academic performance and
    academic self-efficacy were both negatively associated with use of GenAI
    while learned helplessness (that is, the induced inability to solve
    problems that the AI chatbots cannot solve) is associated positively with
    GenAI. This mainly confirms, empirically, facts that are easy to guess from
    the interviews and other sources.
  ]


  #bluebox[@Lake2024AIClassrooms][
    A research publication from the Center for Reinventing Public Education at
    ASU. It mainly discusses the speed of adoption of AI by teachers in
    particular, and barriers to it. This provides some perhaps useful
    statistical data, but the main takeaway from it should be its cavalier
    attitude to AI adoption. Throughout, it only ever considers responses from
    teachers based on their perception of the improvements made by AI, not
    actual empirical data or controlled studies. Indeed, most of the other
    studies examined have shown that AI actually leads to various deleterious
    outcomes in students' personalities and performance. This article, then,
    serves as a good model of the attitude around EdTech and AI---adopt first,
    ask questions later---lest you be left behind by the coming revolution.
  ]

  #bluebox[@Blose2023ProsCons][
    Some data from this article: 1 in 4 teachers have caught students cheating
    u sing ChatGPT or other chatbots. 43% of educators feel that AI will make
    their jobs more difficult while the rest predict it will make their lives
    easier.

    Some experiences from teachers are also provided showcasing how AI is
    materially helping them in the classroom.

    #blockquote[
      “With Chat, you can translate all of the supplementary materials into
      [students'] native language, which makes it far easier for them to complete
      their assignments,” says Shields.
    ]

    #blockquote[
      The chatbot also can rewrite responses at different reading levels. Shields explains that she sent tenth-grade assignments to ChatGPT, asking the chatbot to restructure the material at a sixth-grade level. Her students were then able to follow along and participate in class with their differentiated material.

      “It's really easy now to make different types of assignments,” says Shields.
    ]

    But also concerns:
    #blockquote[
      I think ChatGPT is a crutch that will prevent students from actually needing to learn content. Although I can see its use for small tasks, like how to email a teacher with questions, it also prevents students from developing the soft skills that completing those small tasks allows. ---K--12 teacher
    ]

    This source mainly provides teacher anecdotes both in favor of AI and against. In particular, it does show that there are legitimate uses for the technology in education, but, even in the article some of the uses brought up are immediately arguably unethical.

    #blockquote[
      Shields suggests students evaluate information generated by ChatGPT. Addressing the validity of an AI-generated report will build skills in editing and fact-checking. She also believes teachers should reimagine their assignments.
    ]
    There is an argument against this idea that students should be AI fact-checkers, in #cite(<ButterickCameraObscura2025>, form: "normal").
  ]
]
